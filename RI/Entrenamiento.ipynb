{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "\n",
    "data_entrenamiento = './data/entrenamiento'\n",
    "data_validacion = './data/validacion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "epocas=5 ## número de iteraciones\n",
    "longitud, altura = 150, 150 ## tamaño al que reducimos las imágenes (pixel)\n",
    "batch_size = 32 ## número de imágenes por reconocimiento\n",
    "pasos = 200 ## número de veces de procesamiento, por cada epoca\n",
    "validation_steps = 200 ## al final de cada epoca, otros procesamiento\n",
    "filtrosConv1 = 32 ## número de filtros por convolución (profundidad 32)\n",
    "filtrosConv2 = 64 ## número de filtros por convolución (profundidad 64)\n",
    "tamano_filtro1 = (3, 3)## altura, longitud\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2) ## tamaño de filtro para el pooling\n",
    "clases = 3 ## número de diferentes DLO\n",
    "lr = 0.0004 ## ajuste de la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 3 classes.\n",
      "Found 28 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3825s 19s/step - loss: 0.3256 - acc: 0.9368 - val_loss: 0.1756 - val_acc: 0.8929\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 3613s 18s/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9286\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 3616s 18s/step - loss: 6.8305e-04 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.8929\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 3615s 18s/step - loss: 2.9330e-04 - acc: 1.0000 - val_loss: 0.4942 - val_acc: 0.8214\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 3623s 18s/step - loss: 1.4819e-04 - acc: 1.0000 - val_loss: 0.2164 - val_acc: 0.8929\n"
     ]
    }
   ],
   "source": [
    "##Preparamos nuestras imagenes\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,    ## inclinación\n",
    "    zoom_range=0.2,     ## zoom (parciales)\n",
    "    horizontal_flip=True)   ## inversión\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(clases, activation='softmax'))\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(lr=lr),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "cnn.fit_generator(\n",
    "    entrenamiento_generador,\n",
    "    steps_per_epoch=pasos,\n",
    "    epochs=epocas,\n",
    "    validation_data=validacion_generador,\n",
    "    validation_steps=validation_steps)\n",
    "\n",
    "\n",
    "## Guardamos un archivo con cada clasificación\n",
    "target_dir = './modelo/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
